image: quay.io/ucsc_cgl/toil_ci_prebake:latest
# Note that we must run in a privileged container for our internal Docker daemon to come up.

variables:
  PYTHONIOENCODING: "utf-8"
  DEBIAN_FRONTEND: "noninteractive"
  TOIL_OWNER_TAG: "shared"
  MAIN_PYTHON_PKG: "python3.9"

before_script:
  # Log where we are running, in case some Kubernetes hosts are busted. IPs are assigned per host.
  - ip addr
  # Configure Docker to use a mirror for Docker Hub and restart the daemon
  # Set the registry as insecure because it is probably cluster-internal over plain HTTP.
  - |
    if [[ ! -z "${DOCKER_HUB_MIRROR}" ]] ; then
        echo "{\"registry-mirrors\": [\"${DOCKER_HUB_MIRROR}\"], \"insecure-registries\": [\"${DOCKER_HUB_MIRROR##*://}\"]}" | sudo tee /etc/docker/daemon.json
        export SINGULARITY_DOCKER_HUB_MIRROR="${DOCKER_HUB_MIRROR}"
    fi
  - startdocker || true
  - docker info
  - cat /etc/hosts
  - mkdir -p ~/.kube && cp "$GITLAB_SECRET_FILE_KUBE_CONFIG" ~/.kube/config
  - mkdir -p ~/.aws && cp "$GITLAB_SECRET_FILE_AWS_CREDENTIALS" ~/.aws/credentials
  # We need to make sure docker buildx create can't see the ~/.kube/config that we deploy. It has
  # a service account bearer token for auth and triggers https://github.com/docker/buildx/issues/267
  # where buildx can't use a bearer token from a kube config and falls back to anonymous instead
  # of using the system's service account.
  - KUBECONFIG=/dev/null docker buildx create --use --name toilbuilder --platform=linux/amd64,linux/arm64 --node=buildkit-amd64 --driver=kubernetes --driver-opt="nodeselector=kubernetes.io/arch=amd64"
  # Dump the builder info, and make sure it exists.
  - docker buildx inspect --bootstrap || (echo "Docker builder deployment can't be found in our Kubernetes namespace! Are we on the right Gitlab runner?" && exit 1)
  # This will hang if we can't talk to the builder
  - (echo "y" | docker buildx prune --keep-storage 80G) || true

after_script:
  # We need to clean up any files that Toil may have made via Docker that
  # aren't deletable by the Gitlab user. If we don't do this, Gitlab will try
  # and clean them up before running the next job on the runner, fail, and fail
  # that next job.
  - pwd
  - sudo rm -rf tmp
  - stopdocker || true

stages:
  - basic_tests




#Python3.10
py310_main:
  stage: basic_tests
  script:
    - pwd
    - python3.10 -m virtualenv venv && . venv/bin/activate && curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10 && pip install -U pip wheel && make prepare && make develop extras=[all] packages=htcondor
    - make test tests=src/toil/test/src
    - make test tests=src/toil/test/utils
    - TOIL_SKIP_DOCKER=true make test tests=src/toil/test/lib

py310_appliance_build:
  stage: basic_tests
  script:
    - pwd
    - python3.10 -m virtualenv venv && . venv/bin/activate && curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10 &&  pip install -U pip wheel && make prepare && pip install pycparser && make develop extras=[all] packages='htcondor awscli'
    # This reads GITLAB_SECRET_FILE_QUAY_CREDENTIALS
    - python setup_gitlab_docker.py
    - make push_docker
